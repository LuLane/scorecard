{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SplitData(df, col, numOfSplit, special_attribute=[]):\n",
    "    '''\n",
    "    #等频？\n",
    "    df: 按照col排序后的数据集\n",
    "    col:待分箱的变量\n",
    "    numOfSplit :切分的组别数\n",
    "    special_attribute :在切分数据集的时候，某些特殊值需要排除在外\n",
    "    return ：在原数据集上增加一列，把原始细粒度的col重新划分为粗粒度的值，便于分享中的合并处理\n",
    "    '''\n",
    "    df2 = df.copy()\n",
    "    if special_attribute != []:\n",
    "        df2 = df.loc[~df[col].isin(special_attibute)]\n",
    "    N = df2.shape[0]\n",
    "    n = int(N/numOfSplit)\n",
    "    splitPointIndex = [i * n for i in range(1, numOfSplit)]\n",
    "    rawValues = sorted(list(df2[col]))\n",
    "    splitPoint = [rawValues[i] for i in splitPointIndex]\n",
    "    splitPoint = sorted(list(set(splitPoint)))\n",
    "    return splitPoint\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Chi2(df, total_col, bad_col):\n",
    "    '''\n",
    "    df : 包含全部样本总计与坏样本总计的数据框\n",
    "    total_col : 全部样本的个数\n",
    "    bad_col : 坏样本的个数\n",
    "    return :卡方值\n",
    "    '''\n",
    "    df2 = df.copy()\n",
    "    #求出df中，总体的坏样本率和好样本率\n",
    "    badRate = sum(df2[bad_col])*1.0/sum(df2[total_col])\n",
    "    #当全部样本只有好或者坏样本时，卡方值为0\n",
    "    if badRate in [0,1]:\n",
    "        return 0\n",
    "    df2['good'] = df2.apply(lambda x : x[total_col] - x[bad_col], axis=1)\n",
    "    goodRate = sum(df2['good']) *1.0 / sum(df2[total_col])\n",
    "    #期望坏（好）样本个数 = 全部样本个数*平均坏（好）样本占比\n",
    "    df['badExpected'] = df[total_col].apply(lambda x :x*badRate)\n",
    "    df['goodExpected'] = df[total_col].apply(lambda x: x*goodRate)\n",
    "    badCombined = zip(df2['badExpected'], df2[bad_col])\n",
    "    goodCombined = zip(df2['goodExpected'], df2['good'])\n",
    "    badChi = [(i[0] - i[1]) **2/i[0] for i in badCombined]\n",
    "    goodChi = [(i[0] - i[1]) **2 / i[0] for i in goodCombined]\n",
    "    chi2 = sum(badChi) + sum(goodChi)\n",
    "    return chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BinBadRate(df, col, target, grantRateIndicator=0):\n",
    "    '''\n",
    "    df : 需要计算好坏比率的数据集\n",
    "    col : 需要计算好坏比率的特征\n",
    "    target : 好坏标签\n",
    "    grantRateIndicator : 1返回总体的坏样本率， 0不返回\n",
    "    return ： 每箱的坏样本率，以及总体的坏样本率（当grantRateIndicator == 1时）\n",
    "    '''\n",
    "    total = df.groupby([col])[target].count()\n",
    "    total = pd.DataFrame({\"total\" :total})\n",
    "    bad = df.groupby([col])[target].sum()\n",
    "    bad = pd.DataFrame({\"bad\" : bad})\n",
    "    regroup = total.merge(bad, left_index=True, right_index=True,how=\"left\")#每箱的坏样本数、总样本数\n",
    "    regroup.reset_index(level=0, inplace=True)\n",
    "    regroup['bad_rate'] = regroup.apply(lambda x :x.bad *1.0 /x.total, axis=1)#加上一列坏样本率\n",
    "    dicts = dict(zip(regroup[col], regroup['bad_rate']))#每箱对应的坏样本率组成的字典\n",
    "    if grantRateIndicator == 0:\n",
    "        return (dicts, regroup)\n",
    "    N = sum(regroup['total'])\n",
    "    B = sum(regroup['bad'])\n",
    "    overallRate = B*1.0/N\n",
    "    return (dicts, regroup, overallRate)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chiMerge(df, col, target, max_interval=5, special_attribute=[], minBinPcnt=0):\n",
    "    '''\n",
    "    df : 包含目标变量与分箱属性的数据框\n",
    "    col: 需要分箱的属性\n",
    "    target:目标变量，取值0或1\n",
    "    max_interval:最大分箱数，如果原始属性的取值个数低于该参数，不执行这段函数\n",
    "    special_attribute:不参与分箱的属性取值\n",
    "    minBinPcnt:最小箱的占比，默认为0\n",
    "    return：分箱结果\n",
    "    '''\n",
    "    colLevels = sorted(list(set(df[col])))\n",
    "    N_distinct = len(colLevels)\n",
    "    if N_distinct <= max_interval: #如果原始属性的取值个数低于max_intervals,不执行这段函数\n",
    "        print(\"the number od original level () is less \" .format(col))\n",
    "        print (colLevels[:-1])\n",
    "    else:\n",
    "        if len(special_attribute) >= 1:\n",
    "            df1 = df.loc[df[col].isin(special_attribute)]\n",
    "            df2 = df.loc[~df[col].isin(special_attribute)]\n",
    "        else:\n",
    "            df2 = df.copy()\n",
    "        N_distinct = len(list(set(df2[col])))\n",
    "        #步骤一：通过col对数据集进行分组，求出分组的总样本数与坏样本数\n",
    "        if N_distinct > 100:\n",
    "            split_x = SplitData(df2, col, 100)\n",
    "            df2['temp'] = df2[col].map(lambda x: AssignGroup(x, split_x))\n",
    "            #AssignGroup函数：每一行的数值和切分点做对比，返回原值在切分后的映射，经过map以后，生成该特征的值对象的\n",
    "        else:\n",
    "            df2['temp'] = df2[col]\n",
    "        #总体bad rate 将被用来计算expected bad count\n",
    "        (binBadRate, regroup, overallRate) = BinBatRate(df2, 'temp',target,grantRateIndicator=1)\n",
    "        \n",
    "        #首先，每个单独的属性值将被分为单独的一组\n",
    "        #对属性值进行排序，然后两两组别进行合并\n",
    "        colLevels = sorted(list(set(df2['temp'])))\n",
    "        groupIntervals = [[i] for i in colLevels]\n",
    "        #把每个分箱的值打包成[[], []]的形式\n",
    "        \n",
    "        #步骤二：建立循环，不断合最优的相邻两个组别，直到：\n",
    "        #1.最终分裂出来的箱数<=预设的最大的分箱数\n",
    "        #2.每箱的占比不低于预设值（可选）\n",
    "        #3.每箱同时包含于好坏样本\n",
    "        #4.如果有特殊属性，那么最终分裂出来的分箱数=预设的分箱数-特殊属性的个数\n",
    "        split_intervals = max_interval - len(special_attribute)\n",
    "        while (len(groupIntervals) > split_intervals):\n",
    "            #终止条件：当前分箱数=预设分箱数\n",
    "            #每次循环时，计算合并相邻组别后的卡方值。具有最小卡方值的合并方案是最优方案\n",
    "            chisqList = []\n",
    "            for k in range(len(groupIntervals) -1):\n",
    "                temp_group = groupIntervals[k] + groupIntervals[k+1]\n",
    "                df2b = regroup.loc[regroup['temp'].isin(temp_group)]\n",
    "                chisq = Chi2(df2b, 'total', 'bad')\n",
    "                chisList.append(chisq)\n",
    "            best_combined = chisqList.index(min(chisqList))\n",
    "            \n",
    "            groupIntervals[best_combined] = groupIntervals[best_combined] + groupIntervals[best_combined]\n",
    "            groupIntervals.remove(groupIntervals[best_combined+1])\n",
    "            \n",
    "        groupIntervals = [sort[i] for i in groupIntervals]\n",
    "        cutOffPoints = [max(i) for i in groupIntervals[:-1]]\n",
    "        #检查是否有箱没有坏或者好样本，如果有，需要和相邻的箱进行合并\n",
    "        groupedvalues = df2['temp'].apply(lambda x : AssignBin(x, cutOffPoints))\n",
    "        df2['temp_Bin'] = groupedvalues\n",
    "        (binBadRate, regroup) = BinBadRate(df2, 'temp_Bin', target)\n",
    "        #返回（每箱坏样本率字典和包含列名、坏样本数、总样本数、坏样本率的数据框）\n",
    "        [minBadRate, maxBadRate] = [min(binBadRate.values()), max(binBadRate.values())]\n",
    "        while minBadRate == 0 or maxBadRate ==1:\n",
    "            #找出全部为好/坏样本的箱\n",
    "            indexForBad01 = regroup[regroup['bad_rate'].isin[0,1]]\n",
    "            bin = indexForBBad01[0]\n",
    "            #如果是最后一箱，则需要和上一箱进行合并，也就意味着分裂点最后一个CutOffPoints需要移除\n",
    "            if bin == max(regroup.temp_Bin):\n",
    "                cutOffPoints = cutOffPoints[:-1]\n",
    "            #如果是第一箱，则需要和下一个箱进行合并，也就意味着分裂点cutOffPoints的第一个需要移除\n",
    "            elif bin == min(regroup.temp_Bin):\n",
    "                cutOffPoints = cutOffPoints[1:]\n",
    "            #如果是中间的某一箱，则需要和前后中的一个箱进行合并，依据是较小的卡方值\n",
    "            else:\n",
    "                #和前一箱合并，并且计算卡方值\n",
    "                currentIndex = list(regroup.temp_Bin).index(bin)\n",
    "                prevIndex = list(regroup.temp_Bin)[currentIndex -1]\n",
    "                df3 = df2.loc[df2['temp_Bin'].isin([prevIndex, bin])]\n",
    "                (binBadRate, df2b) = BinBadRate(df3, 'temp_Bin', target)\n",
    "                chisq1 = Chi2(df2b, 'total', 'bad')\n",
    "                #和后一箱合并，计算卡方值\n",
    "                laterIndex = list(regroup.temp_Bin)[currentIndex +1]\n",
    "                df3b = df2.loc[df2['temp_Bin'].isin([laterIndex,bin])]\n",
    "                (binBadRate, df2b) = BinBadRate(df3b, 'temp_Bin', target)\n",
    "                chisq2 = Chi2(df2b, 'total', 'bad')\n",
    "                if chisq1 < chisq2:\n",
    "                    cutOffPoints.remove(cutOffPoints[currentIndex -1])\n",
    "                else:\n",
    "                    cutOffPoints.remove(cutOffPoints[currentIndex])\n",
    "            #完成合并之后，需要再次计算新的分箱准则下，每箱是否同时包含好坏样本\n",
    "            groupedvalues = df2['temp'].apply(lambda x:AssignBin(x, cutOffPOINTS))\n",
    "            df2['temp_Bin'] = groupedvalues\n",
    "            (binBadRate, regroup) = BinBadRate(df2, 'temp_Bin', target)\n",
    "            (minBadRate, maxBadRate) = [min(binBadRate.values()), max(binBadRate.values())]\n",
    "        #需要检查分箱后的最小占比\n",
    "        if minBinPcnt > 0:\n",
    "            groupedvalues = df2['temp'].apply(lambda x : AssignBin(x, cutOffPoins))\n",
    "            df2['temp_Bin'] = groupedvalues\n",
    "            valueCounts = groupedvalues.value_counts().to_frame()\n",
    "            valueCounts['pcnt'] = valueCounts['temp'].apply(lambda x :x*1.0/sum(valueCounts['temp']))\n",
    "            valueCounts = valueCounts.sort_index()\n",
    "            minPcnt = min(valueCounts['pcnt'])\n",
    "            while minPcnt < minBinPcnt and len(cutOffPoints) > 2:\n",
    "                #找出占比最小的箱\n",
    "                indexForMinPcnt = valueCounts[valueCounts['pcnt'] == minPcnt].index.tolist()[0]\n",
    "                #如果最小占比的箱是最后一箱，则需要和上一箱进行合并\n",
    "                if indexForMinPcnt == max(valueCounts.index):\n",
    "                    cutOffPoints = cutOffPoints[:-1]\n",
    "                #如果占比最小的箱是第一箱，则需要和下一箱进行合并\n",
    "                elif indexForMinPcnt == min(valueCounts.index):\n",
    "                    cutOffPoints = cutOffPoints[1:]\n",
    "                #如果占比最小的箱在中间，则需要和前后中的一个箱进行合并，依据是较小的卡方值\n",
    "                else:\n",
    "                    #和前一箱进行合并，计算卡方值\n",
    "                    currentIndex = list(valueCounts.index).index(indexForMinPcnt)\n",
    "                    prevIndex = list(valueCounts.index)[currentIndex -1]\n",
    "                    df3 = df2.loc[df2['temp_Bin'].isin([prevIndex, indexForMinPcnt])]\n",
    "                    (binBadRate, df2b) = BinBadRate(df3, 'temp_Bin', target)\n",
    "                    chisq1 = Chi2(df2b,'taotal','bad')\n",
    "                    #和后一箱进行合并，计算卡方值\n",
    "                    laterIndex = list(valueCounts.index)[currentIndex +1]\n",
    "                    df3b = df2.loc[df2['temp_Bin'].isin([laterIndex, indexForMinPcnt])]\n",
    "                    (binBadRate, df2b) = BinBadRate(df3b, 'temp_Bin',target)\n",
    "                    chisq2 = Chi2(df2b, 'total', 'bad')\n",
    "                    if chisq1 < chisq2:\n",
    "                        cutOffPoints.remove(cutOffPoints[currentIndex -1])\n",
    "                    else:\n",
    "                        cutOffPoints.remove(cutOffPoints[currentIndex +1])\n",
    "                groupedValues = df2['temp'].apply(lambda x:AssignBin(x, cutOffPoints))\n",
    "                df2['temp_Bin'] = groupedvalues()\n",
    "                valueCounts = groupedvalues.value_counts().to_frame()\n",
    "                valueCounts['pcnt'] = valueCounts['temp'].apply(lambda x : x*1.0/sum(valueCounts['temp']))\n",
    "                valueCounts = valueCounts.sort_index()\n",
    "                minPcnt = min(valueCounts['pcnt'])\n",
    "\n",
    "        cutOffPoints = special_attribute + cutOffPoints\n",
    "        return cutOffPoints\n",
    "    \n",
    "                    \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def UnsupervisedSplitBin(df, var, numOfSplit =5, method = 'equal freq'):\n",
    "    '''\n",
    "    df : 数据集\n",
    "    var : 需要分箱的变量，仅限于数值型\n",
    "    numOfSplit : 需要分箱个数，默认是5\n",
    "    method ： 分箱方法，默认是等频，否则等距\n",
    "    '''\n",
    "    if method == 'equal freq':\n",
    "        N = df.shape[0]\n",
    "        n = N/numOfSplit\n",
    "        splitPointIndex = [i * n for i in range(1, numOfSplit)]\n",
    "        rawValues = sorted(list(df[col]))\n",
    "        splitPoint = [rawValues[i] for i in splitPointIndex]\n",
    "        splitPoint = sorted(list(set(splitPoint)))\n",
    "        return splitPoint\n",
    "    else:\n",
    "        var_max, var_min = max(df[var]), min(df[var])\n",
    "        interval_len = (var_max - var_min)*1.0 / numOfSplit\n",
    "        splitPoint = [var_min + i*interval_len for i in range(1, numOfSplit)]\n",
    "        return splitPoint\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AssignGroup(x, bin):\n",
    "    '''\n",
    "    x:某个变量的某个取值\n",
    "    bin:上述变量的分箱结果\n",
    "    return x在分箱结果下的映射\n",
    "    '''\n",
    "    N = len(bin)\n",
    "    if x<min(bin):\n",
    "        return min(bin)\n",
    "    elif x>max(bin):\n",
    "        return 10e10\n",
    "    else:\n",
    "        for i in range(N-1):\n",
    "            if bin[i] < x <= bin[i+1]:\n",
    "                return bin[i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BadRateEncoding(df, col, target):\n",
    "    '''\n",
    "    df : dataframe,包含变量和目标值\n",
    "    col:需要用bad rate编码的变量，通常是分类变量\n",
    "    target : good/bad 指标\n",
    "    return：分类变量的bad rate编码\n",
    "    '''\n",
    "    \n",
    "    regroup = BinBadRate(df, col, target, grantRateIndicator=0)[1]\n",
    "    br_dict = regroup[[col, 'bad_rate']].set_index([col]).to_dict(orient='index')\n",
    "    for k, v in br_dict.items():\n",
    "        br_dict[k] = v['bad_rate']\n",
    "    badRateEncoding = df[col].map(lambda x: br_dict[x])\n",
    "    return {'encoding' : badRateEncoding, 'bad_rate':br_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AssignBin(x, cutOffPoints, special_attribute=[]):\n",
    "    '''\n",
    "    x : 某个变量的某个取值\n",
    "    cutOffPoints :上述变量的分箱结果，用切分点表示\n",
    "    special_attribute:不参与分箱的特殊取值\n",
    "    return:分箱后的对应的第几个箱，从0开始\n",
    "    '''\n",
    "    numBin = len(cutOffPoints) +1 +len(special_attribute)\n",
    "    if x in special_attribute:\n",
    "        i = special_attribute.index(x) +1\n",
    "        return 'Bin {}'.format(0-i)\n",
    "    elif x<=cutOffPoints[0]:\n",
    "        return 'Bin 0'\n",
    "    elif x>cutOffPoints[-1]:\n",
    "        return 'Bin {}'.format(numBin -1)\n",
    "    else:\n",
    "        for i in range(0, numBin -1):\n",
    "            if cutOffPoints[i] <x<=CutOffPoints[i+1]:\n",
    "                return 'Bin {}'.format(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CalcWOE(df, col, target):\n",
    "    '''\n",
    "    df: 包含需要计算WOE的变量和目标变量\n",
    "    col : 需要计算WOE、IV的变量，必须是分箱后的变量\n",
    "    target : 目标变量,0/1表示好/坏\n",
    "    return :返回woe和iv\n",
    "    '''\n",
    "    total = df.groupby([col])[target].count()\n",
    "    total = pd.DataFrame({'total' : total})\n",
    "    bad = df.groupby([col])[target].sum()\n",
    "    bad = pd.DataFrame({'bad' : bad})\n",
    "    regroup = total.merge(bad, lef_index=True, right_index=True, how='left')\n",
    "    regoup.reset_index(level=0, inplace=True)\n",
    "    N = sum(regroup['total'])\n",
    "    B = sum(regroup['bad'])\n",
    "    regroup['good'] = regroup['total'] - regroup['bad']\n",
    "    G = N - B\n",
    "    regroup['bad_pcnt'] = regroup['bad'].map(lambda x : x*1.0/B)\n",
    "    regroup['good_pcnt'] = regroup['good'].map(lambda x : x*1.0/G)\n",
    "    WOE_dict = regroup[[col,'WOE']].set_index(col).to_dict(orient='index')\n",
    "    for k, v in WOE_dict.items():\n",
    "        WOE_dict[k] = v['WOE']\n",
    "    IV = regroup.apply(lambda x:(x.good_pcnt - x.bad_pcnt) * np.log(x.good_pcnt/x.bad_pcnt), axis=1)\n",
    "    IV = sum(IV)\n",
    "    return {'WOE' : WOE_dict, \"IV\" : IV}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#判断某变量的坏样本率是否单调\n",
    "def BadRateMonotone(df, sortByVar, target, special_attribute =[]):\n",
    "    '''\n",
    "    df : 包含检验坏样本率的变量和目标变量\n",
    "    sortByVar : 需要检验坏样本率的变量\n",
    "    target：目标变量\n",
    "    special_attribute:不参与检验的特殊值\n",
    "    return :坏样本率单调与否\n",
    "    '''\n",
    "    df2 = df.loc[~df[sortByVar].isin(special_attribute)]\n",
    "    if len(set(df2[sortByVar])) <=2:\n",
    "        return True\n",
    "    regroup = BinBadRate(df2, sortByVar, target)[1]\n",
    "    combined = zip(regroup['total'], regroup['bad'])\n",
    "    badRate = [x[1]*1.0 /x[0] for x in combined]\n",
    "    badRateNotMonotone = [badRate[i] < badRate[i+1] and badRate[i] < badRate[i-1] or\n",
    "                         badRate[i] > badRate[i+1] and badRate[i] <badRate[i] < badRate[i-1]]\n",
    "    if True in badRateNotMonotone:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MergeBad0(df, col, target, direction='bad'):\n",
    "    '''\n",
    "    df:包含检验0%和100%坏样本率\n",
    "    col:分箱后的变量或者类别型变量，检验其中一组或者多组没有坏样本或好样本，如果是则需要合并\n",
    "    target:目标变量\n",
    "    direction:合并方案，使得每个组里同时包含好坏样本\n",
    "    '''\n",
    "    regroup = BinBadRate(df, col, target)[1]\n",
    "    if direction == 'bad':\n",
    "        # 如果是合并0坏样本率的组，则跟最小的非0坏样本率的组进行合并\n",
    "        regroup = regroup.sort_values(by='bad_rate')\n",
    "    else:\n",
    "        #如果是合并0好样本率的组，则跟最小的非0好样本率的组进行合并\n",
    "        regroup = regroup.sort_values(by='bad_rate', ascending=False)\n",
    "    regroup.index = range(regroup.shape[0])\n",
    "    col_regroup = [[i] for i in regroup[col]]\n",
    "    del_index = []\n",
    "    for i in range(regroup.shape[0]-1):\n",
    "        col_regroup[i+1] = col_regroup[i] + col_regroup[i+1]\n",
    "        del_index.append[i]\n",
    "        if direction == 'bad':\n",
    "            if regroup['bad_rate'][i+1]>0:\n",
    "                break\n",
    "        else:\n",
    "            if regroup['bad_rate'][i+1]<1:\n",
    "                break\n",
    "    col_regroup2 = [col_regroup[i] for i in range(len(col_regroup)) if i not in del_index]\n",
    "    newGroup = {}\n",
    "    for i in range(len(col_regroup2)):\n",
    "        for g2 in col_regroup2[i]:\n",
    "            newGroup[g2] = 'Bin' + str[i]\n",
    "    return newGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Prob2Score(prob, basePoint, PDO):\n",
    "    #将概率转化为分数且为正整数\n",
    "    y = np.log(prob/(1-prob))\n",
    "    return int(basePoint+PDO/np.log(2)*(-y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#计算KS值\n",
    "def KS(df, score, target):\n",
    "    '''\n",
    "    df : 包含目标变量与预测值的数据集\n",
    "    score : 得分或概率\n",
    "    target ： 目标变量\n",
    "    return ： ks值\n",
    "    '''\n",
    "    total = df.groupby([score])[target].count()\n",
    "    bad = df.groupby([score])[target].sum()\n",
    "    all = pd.DataFrame({'total' : total, \"bad\" : bad})\n",
    "    all['good'] = all[total] - all['bad']\n",
    "    all[score] = all.index\n",
    "    all = all.sort_values(by=score, ascending=False)\n",
    "    all.index = range(len(all))\n",
    "    all['badCumRate'] = all['bad'].cumsum()/all['bad'].sum()\n",
    "    all['goodCumRate'] = all['good'].cumsun()/all['good'].sum()\n",
    "    KS = all.apply(lambda x: x.badCumRate - x.goodCumRate, axis=1)\n",
    "    return max(KS)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MergeByCondition(x, condition_list):\n",
    "    #condition_list是条件列表，满足第几个condition，就输出几\n",
    "    s = 0\n",
    "    for condition in conditionn_list:\n",
    "        if eval(str(x) + condition):\n",
    "            return s\n",
    "        else:\n",
    "            s +=1\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
